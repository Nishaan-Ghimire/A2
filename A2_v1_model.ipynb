{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEhiIQZmPDrZbSe/Ss1eW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishaan-Ghimire/A2/blob/main/A2_v1_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSfvAm-0ZkFN",
        "outputId": "befcc51a-bc96-4381-fddf-34073c76412c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J9B2U-KzZVQF"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ricardosalvatorelli1/paddydoctor -p /content/drive/MyDrive/KaggleDatasets --unzip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JuWTfa7apF0",
        "outputId": "8c4bc3c5-1e37-4588-cae2-45e22271a555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ricardosalvatorelli1/paddydoctor\n",
            "License(s): unknown\n",
            "User cancelled operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import (\n",
        "    EfficientNetV2B3, EfficientNetV2M, EfficientNetV2L,\n",
        "    ConvNeXtBase, ConvNeXtLarge,\n",
        "    ResNet152V2, DenseNet201,\n",
        "    InceptionResNetV2\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, GlobalAveragePooling2D, BatchNormalization,\n",
        "    MultiHeadAttention, LayerNormalization, Add, Reshape, Permute,\n",
        "    Conv2D, DepthwiseConv2D, Activation\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import AdamW, Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ReduceLROnPlateau, EarlyStopping, ModelCheckpoint,\n",
        "    TensorBoard, CSVLogger\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "12SPpVJuGNrM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    import cv2\n",
        "except ImportError:\n",
        "    print(\"üì¶ Installing opencv...\")\n",
        "    os.system(\"pip install opencv-python\")\n",
        "    import cv2\n",
        "\n",
        "# === T4 GPU COLAB OPTIMIZED CONFIG üî• ===\n",
        "# Maxed out for free T4 GPU while being memory-safe\n",
        "IMG_SIZE = 384      # Sweet spot for T4 - big enough to be compute heavy\n",
        "BATCH_SIZE = 6      # Optimized for T4's 16GB VRAM\n",
        "EPOCHS = 100        # Enough to get good results\n",
        "TRAIN_DATA_DIR = \"/content/drive/MyDrive/KaggleDatasets/train_images/\"\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/KaggleDatasets/test_images/\"\n",
        "NUM_CLASSES = 10\n",
        "MODELS_TO_ENSEMBLE = 3  # Train multiple models for ensemble\n",
        "\n",
        "# Enable mixed precision for MAXIMUM SPEED üöÄ\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# Setup logging with cool emojis\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "A0ypSllBNvOx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class HeavyAugmentation:\n",
        "    \"\"\"Augmentation pipeline that'll make your data unrecognizable üòà\"\"\"\n",
        "\n",
        "    def __init__(self, img_size=384):\n",
        "        self.img_size = img_size\n",
        "        self.augment = A.Compose([\n",
        "            # Geometric transforms\n",
        "            A.RandomResizedCrop(img_size, img_size, scale=(0.6, 1.0), p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.2),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.Rotate(limit=30, p=0.7),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.2,\n",
        "                scale_limit=0.2,\n",
        "                rotate_limit=30,\n",
        "                p=0.8\n",
        "            ),\n",
        "\n",
        "            # Color augmentations - make it spicy üå∂Ô∏è\n",
        "            A.RandomBrightnessContrast(\n",
        "                brightness_limit=0.3,\n",
        "                contrast_limit=0.3,\n",
        "                p=0.8\n",
        "            ),\n",
        "            A.HueSaturationValue(\n",
        "                hue_shift_limit=20,\n",
        "                sat_shift_limit=30,\n",
        "                val_shift_limit=20,\n",
        "                p=0.8\n",
        "            ),\n",
        "            A.RGBShift(\n",
        "                r_shift_limit=20,\n",
        "                g_shift_limit=20,\n",
        "                b_shift_limit=20,\n",
        "                p=0.7\n",
        "            ),\n",
        "            A.ColorJitter(\n",
        "                brightness=0.2,\n",
        "                contrast=0.2,\n",
        "                saturation=0.2,\n",
        "                hue=0.1,\n",
        "                p=0.7\n",
        "            ),\n",
        "\n",
        "            # Noise and blur - chaos mode activated üíÄ\n",
        "            A.OneOf([\n",
        "                A.GaussNoise(var_limit=(10, 50)),\n",
        "                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5)),\n",
        "            ], p=0.6),\n",
        "\n",
        "            A.OneOf([\n",
        "                A.GaussianBlur(blur_limit=5),\n",
        "                A.MotionBlur(blur_limit=5),\n",
        "                A.MedianBlur(blur_limit=3),\n",
        "            ], p=0.4),\n",
        "\n",
        "            # Geometric distortions\n",
        "            A.OpticalDistortion(distort_limit=0.2, shift_limit=0.2, p=0.4),\n",
        "            A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.4),\n",
        "            A.ElasticTransform(\n",
        "                alpha=120,\n",
        "                sigma=120 * 0.05,\n",
        "                alpha_affine=120 * 0.03,\n",
        "                p=0.4\n",
        "            ),\n",
        "\n",
        "            # Cutout variants - randomly remove patches\n",
        "            A.CoarseDropout(\n",
        "                max_holes=8,\n",
        "                max_height=24,\n",
        "                max_width=24,\n",
        "                fill_value=0,\n",
        "                p=0.6\n",
        "            ),\n",
        "            A.Cutout(\n",
        "                num_holes=12,\n",
        "                max_h_size=24,\n",
        "                max_w_size=24,\n",
        "                fill_value=0,\n",
        "                p=0.5\n",
        "            ),\n",
        "\n",
        "            # Weather effects for extra spice\n",
        "            A.RandomShadow(p=0.3),\n",
        "            A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.2, p=0.2),\n",
        "            A.RandomSunFlare(p=0.1),\n",
        "            A.RandomRain(p=0.1),\n",
        "\n",
        "            # Normalize at the end\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if isinstance(image, np.ndarray):\n",
        "            return self.augment(image=image)['image']\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "jHMi9LRMN1YQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomTransformerBlock:\n",
        "    \"\"\"Custom transformer layers because we're fancy like that ‚ú®\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def attention_block(x, num_heads=12, key_dim=64, dropout_rate=0.1):\n",
        "        # Multi-head self-attention\n",
        "        attn_output = MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=key_dim,\n",
        "            dropout=dropout_rate,\n",
        "            name=f'mha_{np.random.randint(1000)}'\n",
        "        )(x, x)\n",
        "\n",
        "        # Add & Norm\n",
        "        x = Add()([x, attn_output])\n",
        "        x = LayerNormalization()(x)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        ffn = Sequential([\n",
        "            Dense(x.shape[-1] * 4, activation='gelu'),\n",
        "            Dropout(dropout_rate),\n",
        "            Dense(x.shape[-1])\n",
        "        ])\n",
        "\n",
        "        ffn_output = ffn(x)\n",
        "        x = Add()([x, ffn_output])\n",
        "        x = LayerNormalization()(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "r7oWaRwYX9Dx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class T4ModelBuilder:\n",
        "    \"\"\"Build models that'll make your T4 GPU work hard but not crash üî•\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, img_size=384):\n",
        "        self.num_classes = num_classes\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def build_efficientnet_v2_beast(self):\n",
        "        \"\"\"EfficientNetV2-L with custom head - The Big Boss üëë\"\"\"\n",
        "        logger.info(\"üöÄ Building EfficientNetV2-L Beast Model\")\n",
        "\n",
        "        base_model = EfficientNetV2L(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(self.img_size, self.img_size, 3)\n",
        "        )\n",
        "\n",
        "        # Unfreeze last 80 layers for fine-tuning\n",
        "        for layer in base_model.layers[-80:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "\n",
        "        # Transform for attention\n",
        "        x = Dense(768, name='transformer_proj')(x)\n",
        "        x = Reshape((1, 768))(x)\n",
        "\n",
        "        # Add transformer blocks\n",
        "        x = CustomTransformerBlock.attention_block(x, num_heads=12, key_dim=64)\n",
        "        x = CustomTransformerBlock.attention_block(x, num_heads=8, key_dim=96)\n",
        "\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "        # Dense layers with different activations\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(2048, activation='gelu', name='dense_2048')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(1024, activation='swish', name='dense_1024')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(512, activation='mish', name='dense_512')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        predictions = Dense(\n",
        "            self.num_classes,\n",
        "            activation='softmax',\n",
        "            dtype='float32',\n",
        "            name='predictions'\n",
        "        )(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        return model\n",
        "\n",
        "    def build_convnext_monster(self):\n",
        "        \"\"\"ConvNeXt-Large - The Convolution King üëπ\"\"\"\n",
        "        logger.info(\"üî• Building ConvNeXt Large Monster\")\n",
        "\n",
        "        base_model = ConvNeXtLarge(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(self.img_size, self.img_size, 3)\n",
        "        )\n",
        "\n",
        "        # Fine-tune the entire model\n",
        "        base_model.trainable = True\n",
        "\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "        # Multiple dense layers with batch norm\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.6)(x)\n",
        "        x = Dense(3072, activation='gelu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(1536, activation='swish')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(768, activation='mish')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        predictions = Dense(\n",
        "            self.num_classes,\n",
        "            activation='softmax',\n",
        "            dtype='float32'\n",
        "        )(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        return model\n",
        "\n",
        "    def build_inception_resnet_hybrid(self):\n",
        "        \"\"\"InceptionResNetV2 with custom attention - The Hybrid Beast ü§ñ\"\"\"\n",
        "        logger.info(\"üß† Building InceptionResNetV2 Hybrid\")\n",
        "\n",
        "        base_model = InceptionResNetV2(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(self.img_size, self.img_size, 3)\n",
        "        )\n",
        "\n",
        "        # Unfreeze last 100 layers\n",
        "        for layer in base_model.layers[-100:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "        # Add some custom convolution magic\n",
        "        x = Dense(1024)(x)\n",
        "        x = Reshape((1, 1024))(x)\n",
        "\n",
        "        # Attention mechanism\n",
        "        x = CustomTransformerBlock.attention_block(x, num_heads=16, key_dim=64)\n",
        "\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(2048, activation='gelu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(1024, activation='swish')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        predictions = Dense(\n",
        "            self.num_classes,\n",
        "            activation='softmax',\n",
        "            dtype='float32'\n",
        "        )(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        return model\n",
        "\n",
        "    def build_densenet_enhanced(self):\n",
        "        \"\"\"DenseNet201 Enhanced - Dense but Smart üßÆ\"\"\"\n",
        "        logger.info(\"üìä Building Enhanced DenseNet201\")\n",
        "\n",
        "        base_model = DenseNet201(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(self.img_size, self.img_size, 3)\n",
        "        )\n",
        "\n",
        "        # Fine-tune last layers\n",
        "        for layer in base_model.layers[-60:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "        # Enhanced dense layers\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(2048, activation='gelu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(1024, activation='swish')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(512, activation='mish')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        predictions = Dense(\n",
        "            self.num_classes,\n",
        "            activation='softmax',\n",
        "            dtype='float32'\n",
        "        )(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "LC6puOpRYGY5"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class T4Trainer:\n",
        "    \"\"\"Training pipeline optimized for T4 GPU üéØ\"\"\"\n",
        "\n",
        "    def __init__(self, model, model_name, data_dir, img_size=384, batch_size=6):\n",
        "        self.model = model\n",
        "        self.model_name = model_name\n",
        "        self.data_dir = data_dir\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    def setup_data_generators(self):\n",
        "        \"\"\"Setup data generators with INSANE augmentation üå™Ô∏è\"\"\"\n",
        "\n",
        "        # Custom preprocessing function\n",
        "        def preprocess_input(x):\n",
        "            return HeavyAugmentation(self.img_size)(x)\n",
        "\n",
        "        # Training generator\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split=0.2,\n",
        "            preprocessing_function=preprocess_input if hasattr(self, 'use_heavy_aug') else None\n",
        "        )\n",
        "\n",
        "        # Validation generator (no augmentation)\n",
        "        val_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        self.train_gen = train_datagen.flow_from_directory(\n",
        "            self.data_dir,\n",
        "            target_size=(self.img_size, self.img_size),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='training',\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        self.val_gen = val_datagen.flow_from_directory(\n",
        "            self.data_dir,\n",
        "            target_size=(self.img_size, self.img_size),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='validation',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        logger.info(f\"üìä Training samples: {self.train_gen.samples}\")\n",
        "        logger.info(f\"üìä Validation samples: {self.val_gen.samples}\")\n",
        "\n",
        "    def compile_model(self):\n",
        "        \"\"\"Compile with advanced optimizer üöÄ\"\"\"\n",
        "\n",
        "        # Calculate steps for learning rate schedule\n",
        "        steps_per_epoch = self.train_gen.samples // self.batch_size\n",
        "        total_steps = steps_per_epoch * 80  # 80 epochs for schedule\n",
        "\n",
        "        # Cosine decay learning rate\n",
        "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "            initial_learning_rate=2e-4,\n",
        "            decay_steps=total_steps,\n",
        "            alpha=1e-6\n",
        "        )\n",
        "\n",
        "        # AdamW optimizer for better generalization\n",
        "        optimizer = AdamW(\n",
        "            learning_rate=lr_schedule,\n",
        "            weight_decay=1e-4,\n",
        "            beta_1=0.9,\n",
        "            beta_2=0.999,\n",
        "            epsilon=1e-7\n",
        "        )\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy', 'top_2_categorical_accuracy']\n",
        "        )\n",
        "\n",
        "        logger.info(\"‚úÖ Model compiled with AdamW optimizer\")\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Callbacks for monitoring and saving üìà\"\"\"\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint(\n",
        "                f'best_{self.model_name}_{self.timestamp}.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                save_weights_only=False,\n",
        "                verbose=1,\n",
        "                mode='max'\n",
        "            ),\n",
        "\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.3,\n",
        "                patience=7,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1,\n",
        "                cooldown=3\n",
        "            ),\n",
        "\n",
        "            EarlyStopping(\n",
        "                monitor='val_accuracy',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1,\n",
        "                mode='max',\n",
        "                min_delta=0.001\n",
        "            ),\n",
        "\n",
        "            CSVLogger(\n",
        "                f'training_log_{self.model_name}_{self.timestamp}.csv',\n",
        "                append=True\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        return callbacks\n",
        "\n",
        "    def train(self, epochs=100):\n",
        "        \"\"\"The training that'll make your T4 GPU sweat üí™\"\"\"\n",
        "\n",
        "        logger.info(f\"üöÄ Starting training for {self.model_name}\")\n",
        "        logger.info(\"Get ready for some serious GPU workout! üî•\")\n",
        "\n",
        "        self.setup_data_generators()\n",
        "        self.compile_model()\n",
        "        callbacks = self.setup_callbacks()\n",
        "\n",
        "        # Print model info\n",
        "        total_params = self.model.count_params()\n",
        "        trainable_params = sum([tf.keras.backend.count_params(w) for w in self.model.trainable_weights])\n",
        "\n",
        "        print(f\"üìä Total parameters: {total_params:,}\")\n",
        "        print(f\"üìä Trainable parameters: {trainable_params:,}\")\n",
        "        print(f\"üéØ Image size: {self.img_size}x{self.img_size}\")\n",
        "        print(f\"üì¶ Batch size: {self.batch_size}\")\n",
        "\n",
        "        history = self.model.fit(\n",
        "            self.train_gen,\n",
        "            validation_data=self.val_gen,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"Comprehensive evaluation with plots üìä\"\"\"\n",
        "\n",
        "        logger.info(\"üìä Evaluating model performance\")\n",
        "\n",
        "        # Reset generator\n",
        "        self.val_gen.reset()\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = self.model.predict(self.val_gen, verbose=1)\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_true = self.val_gen.classes\n",
        "\n",
        "        # Get class names\n",
        "        class_names = list(self.val_gen.class_indices.keys())\n",
        "\n",
        "        # Classification report\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üéØ CLASSIFICATION REPORT\")\n",
        "        print(\"=\"*60)\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names\n",
        "        )\n",
        "        plt.title(f'Confusion Matrix - {self.model_name}', fontsize=16)\n",
        "        plt.ylabel('True Label', fontsize=12)\n",
        "        plt.xlabel('Predicted Label', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'confusion_matrix_{self.model_name}_{self.timestamp}.png', dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
        "        print(f\"\\nüéØ Final Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "COjSlYrxYYp8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def setup_gpu_memory():\n",
        "    \"\"\"Configure GPU memory for T4 optimization üéÆ\"\"\"\n",
        "\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "    if physical_devices:\n",
        "        try:\n",
        "            # Enable memory growth\n",
        "            tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "            # Optional: Set memory limit (uncomment if you get OOM errors)\n",
        "            # tf.config.experimental.set_virtual_device_configuration(\n",
        "            #     physical_devices[0],\n",
        "            #     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=14000)]\n",
        "            # )\n",
        "\n",
        "            print(f\"üéÆ GPU configured: {physical_devices[0]}\")\n",
        "            print(\"üíö Memory growth enabled for T4 optimization\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"‚ö†Ô∏è GPU configuration error: {e}\")\n",
        "    else:\n",
        "        print(\"‚ùå No GPU found! This will be slow on CPU\")\n"
      ],
      "metadata": {
        "id": "9nEveOaaYc5z"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the T4-optimized pipeline üöÄ\"\"\"\n",
        "\n",
        "    print(\"üî•\" * 20)\n",
        "    print(\"T4 GPU OPTIMIZED TRAINING PIPELINE\")\n",
        "    print(\"Free Colab Edition - Max Performance! üí™\")\n",
        "    print(\"üî•\" * 20)\n",
        "\n",
        "    # Setup GPU\n",
        "    setup_gpu_memory()\n",
        "\n",
        "    # Initialize model builder\n",
        "    builder = T4ModelBuilder(num_classes=NUM_CLASSES, img_size=IMG_SIZE)\n",
        "\n",
        "    # Models to train (all Colab compatible)\n",
        "    models_to_train = [\n",
        "        ('EfficientNetV2L_Beast', builder.build_efficientnet_v2_beast),\n",
        "        ('ConvNeXt_Large_Monster', builder.build_convnext_monster),\n",
        "        ('InceptionResNetV2_Hybrid', builder.build_inception_resnet_hybrid),\n",
        "        ('DenseNet201_Enhanced', builder.build_densenet_enhanced),\n",
        "    ]\n",
        "\n",
        "    trained_models = {}\n",
        "\n",
        "    for i, (model_name, model_builder) in enumerate(models_to_train):\n",
        "        print(f\"\\nüöÄ Training Model {i+1}/{len(models_to_train)}: {model_name}\")\n",
        "        print(\"Time to make that T4 work! üí™\")\n",
        "\n",
        "        try:\n",
        "            # Build model\n",
        "            model = model_builder()\n",
        "\n",
        "            # Train model\n",
        "            trainer = T4Trainer(model, model_name, TRAIN_DATA_DIR, IMG_SIZE, BATCH_SIZE)\n",
        "            history = trainer.train(epochs=EPOCHS)\n",
        "\n",
        "            # Evaluate\n",
        "            trainer.evaluate_model()\n",
        "\n",
        "            trained_models[model_name] = {\n",
        "                'model': model,\n",
        "                'history': history,\n",
        "                'trainer': trainer\n",
        "            }\n",
        "\n",
        "            print(f\"‚úÖ {model_name} training completed!\")\n",
        "\n",
        "            # Clear memory after each model (important for Colab)\n",
        "            tf.keras.backend.clear_session()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Failed to train {model_name}: {str(e)}\")\n",
        "            tf.keras.backend.clear_session()\n",
        "            continue\n",
        "\n",
        "    print(\"\\nüéâ T4 TRAINING PIPELINE COMPLETE! üéâ\")\n",
        "    print(\"Your free T4 GPU just got a serious workout! üí™\")\n",
        "    print(f\"Successfully trained {len(trained_models)} models üî•\")\n"
      ],
      "metadata": {
        "id": "ts6I_FGGYg3f"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhSFZ9XcYkc4",
        "outputId": "6be6f2fa-8bad-4098-9409-e5dd87fd42cb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•\n",
            "T4 GPU OPTIMIZED TRAINING PIPELINE\n",
            "Free Colab Edition - Max Performance! üí™\n",
            "üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•\n",
            "üéÆ GPU configured: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "üíö Memory growth enabled for T4 optimization\n",
            "\n",
            "üöÄ Training Model 1/4: EfficientNetV2L_Beast\n",
            "Time to make that T4 work! üí™\n",
            "Found 8330 images belonging to 10 classes.\n",
            "Found 2077 images belonging to 10 classes.\n",
            "üìä Total parameters: 137,120,682\n",
            "üìä Trainable parameters: 136,602,474\n",
            "üéØ Image size: 384x384\n",
            "üì¶ Batch size: 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "ERROR:__main__:‚ùå Failed to train EfficientNetV2L_Beast: Could not interpret metric identifier: top_2_categorical_accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Training Model 2/4: ConvNeXt_Large_Monster\n",
            "Time to make that T4 work! üí™\n",
            "Found 8330 images belonging to 10 classes.\n",
            "Found 2077 images belonging to 10 classes.\n",
            "üìä Total parameters: 206,884,810\n",
            "üìä Trainable parameters: 206,872,522\n",
            "üéØ Image size: 384x384\n",
            "üì¶ Batch size: 6\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:‚ùå Failed to train ConvNeXt_Large_Monster: Could not interpret metric identifier: top_2_categorical_accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Training Model 3/4: InceptionResNetV2_Hybrid\n",
            "Time to make that T4 work! üí™\n",
            "Found 8330 images belonging to 10 classes.\n",
            "Found 2077 images belonging to 10 classes.\n",
            "üìä Total parameters: 72,726,762\n",
            "üìä Trainable parameters: 72,660,074\n",
            "üéØ Image size: 384x384\n",
            "üì¶ Batch size: 6\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 16, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "ERROR:__main__:‚ùå Failed to train InceptionResNetV2_Hybrid: Could not interpret metric identifier: top_2_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Training Model 4/4: DenseNet201_Enhanced\n",
            "Time to make that T4 work! üí™\n",
            "Found 8330 images belonging to 10 classes.\n",
            "Found 2077 images belonging to 10 classes.\n",
            "üìä Total parameters: 24,904,266\n",
            "üìä Trainable parameters: 24,665,226\n",
            "üéØ Image size: 384x384\n",
            "üì¶ Batch size: 6\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:‚ùå Failed to train DenseNet201_Enhanced: Could not interpret metric identifier: top_2_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ T4 TRAINING PIPELINE COMPLETE! üéâ\n",
            "Your free T4 GPU just got a serious workout! üí™\n",
            "Successfully trained 0 models üî•\n"
          ]
        }
      ]
    }
  ]
}